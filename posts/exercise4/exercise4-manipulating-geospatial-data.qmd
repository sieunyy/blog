---
title: "Exercise4: Manipulating Geospatial Data"
author: "Sieun Shim"
date: "2023-05-01"
categories: [code, geopandas]
toc: true
jupyter: python3
---

> Kaggle Geospatial Analysis Exercise4

**This notebook is an exercise in the [Geospatial Analysis](https://www.kaggle.com/learn/geospatial-analysis) course.  You can reference the tutorial at [this link](https://www.kaggle.com/alexisbcook/manipulating-geospatial-data).**

---


# Introduction

You are a Starbucks big data analyst ([thatâ€™s a real job!](https://www.forbes.com/sites/bernardmarr/2018/05/28/starbucks-using-big-data-analytics-and-artificial-intelligence-to-boost-performance/#130c7d765cdc)) looking to find the next store into a [Starbucks Reserve Roastery](https://www.businessinsider.com/starbucks-reserve-roastery-compared-regular-starbucks-2018-12#also-on-the-first-floor-was-the-main-coffee-bar-five-hourglass-like-units-hold-the-freshly-roasted-coffee-beans-that-are-used-in-each-order-the-selection-rotates-seasonally-5).  These roasteries are much larger than a typical Starbucks store and have several additional features, including various food and wine options, along with upscale lounge areas.  You'll investigate the demographics of various counties in the state of California, to determine potentially suitable locations.

<center>
<img src="https://storage.googleapis.com/kaggle-media/learn/images/BIyE6kR.png" width="450"><br/><br/>
</center>

Before you get started, run the code cell below to set everything up.


```{python}
import math
import numpy as np
import pandas as pd
import geopandas as gpd
from geopy.geocoders import Nominatim            # What you'd normally run

import folium 
from folium import Marker
from folium.plugins import MarkerCluster
```

You'll use the `embed_map()` function from the previous exercise to visualize your maps.

```{python}
def embed_map(m, file_name):
    from IPython.display import IFrame
    m.save(file_name)
    return IFrame(file_name, width = '100%', height = '500px')
```

# Exercises

### 1) Geocode the missing locations.

Run the next code cell to create a DataFrame `starbucks` containing Starbucks locations in the state of California.

```{python}
# Load and preview Starbucks locations in California
starbucks = pd.read_csv("../../../spatial_analysis/data/starbucks_locations.csv")
starbucks.head()
```

Most of the stores have known (latitude, longitude) locations.  But, all of the locations in the city of Berkeley are missing.

```{python}
# How many rows in each column have missing values?
print(starbucks.isnull().sum())

# View rows with missing locations
rows_with_missing = starbucks[starbucks["City"] == "Berkeley"]
rows_with_missing
```

Use the code cell below to fill in these values with the Nominatim geocoder.

Note that in the tutorial, we used `Nominatim()` (from `geopy.geocoders`) to geocode values, and this is what you can use in your own projects outside of this course.  

In this exercise, you will use a slightly different function `Nominatim()` (from `learntools.geospatial.tools`).  This function was imported at the top of the notebook and works identically to the function from GeoPandas.

So, in other words, as long as: 
- you don't change the import statements at the top of the notebook, and 
- you call the geocoding function as `geocode()` in the code cell below, 

your code will work as intended!

```{python}
# Create the geocoder
geolocator = Nominatim(user_agent = "kaggle_learn")

def my_geocoder(row):
    try:
        point = geolocator.geocode(row).point
        return pd.Series({'Latitude': point.latitude, 'Longitude': point.longitude})
    except:
        return None

rows_with_missing[['Latitude', 'Longitude']] = rows_with_missing.apply(lambda x: my_geocoder(x['Address']), axis = 1)

starbucks.update(rows_with_missing[['Latitude', 'Longitude']])

print("{}% of addresses were geocoded!".format(
    (1 - sum(np.isnan(starbucks["Latitude"])) / len(starbucks)) * 100))
```

```{python}
starbucks.head()
```

### 2) View Berkeley locations.

Let's take a look at the locations you just found.  Visualize the (latitude, longitude) locations in Berkeley in the OpenStreetMap style. 

```{python}
# Create a base map
m_2 = folium.Map(location = [37.88, -122.26], zoom_start = 13)

# Add a marker for each Berkeley location
for idx, row in starbucks[starbucks['City'] == 'Berkeley'].iterrows():
    Marker([row['Latitude'], row['Longitude']], popup = row['Store Name']).add_to(m_2)

# Show the map
embed_map(m_2, 'q_2.html')

m_2
```

Considering only the five locations in Berkeley, how many of the (latitude, longitude) locations seem potentially correct (are located in the correct city)?

### 3) Consolidate your data.

Run the code below to load a GeoDataFrame `CA_counties` containing the name, area (in square kilometers), and a unique id (in the "GEOID" column) for each county in the state of California.  The "geometry" column contains a polygon with county boundaries.

```{python}
CA_counties = gpd.read_file("../../../spatial_analysis/data/CA_county_boundaries/CA_county_boundaries/CA_county_boundaries.shp")
CA_counties.crs = {'init': 'epsg:4326'}
CA_counties.head()
```

Next, we create three DataFrames:
- `CA_pop` contains an estimate of the population of each county.
- `CA_high_earners` contains the number of households with an income of at least $150,000 per year.
- `CA_median_age` contains the median age for each county.

```{python}
CA_pop = pd.read_csv("../../../spatial_analysis/data/CA_county_population.csv", index_col="GEOID")
CA_high_earners = pd.read_csv("../../../spatial_analysis/data/CA_county_high_earners.csv", index_col="GEOID")
CA_median_age = pd.read_csv("../../../spatial_analysis/data/CA_county_median_age.csv", index_col="GEOID")
```

Use the next code cell to join the `CA_counties` GeoDataFrame with `CA_pop`, `CA_high_earners`, and `CA_median_age`.

Name the resultant GeoDataFrame `CA_stats`, and make sure it has 8 columns: "GEOID", "name", "area_sqkm", "geometry", "population", "high_earners", and "median_age".  

```{python}
CA_join = CA_pop.join([CA_high_earners, CA_median_age]).reset_index()
CA_stats = CA_counties.merge(CA_join, on = "GEOID")
CA_stats.head()
```

Now that we have all of the data in one place, it's much easier to calculate statistics that use a combination of columns.  Run the next code cell to create a "density" column with the population density.

```{python}
CA_stats["density"] = CA_stats["population"] / CA_stats["area_sqkm"]
CA_stats.head()
```

### 4) Which counties look promising?

Collapsing all of the information into a single GeoDataFrame also makes it much easier to select counties that meet specific criteria.

Use the next code cell to create a GeoDataFrame `sel_counties` that contains a subset of the rows (and all of the columns) from the `CA_stats` GeoDataFrame.  In particular, you should select counties where:
- there are at least 100,000 households making \$150,000 per year,
- the median age is less than 38.5, and
- the density of inhabitants is at least 285 (per square kilometer).

Additionally, selected counties should satisfy at least one of the following criteria:
- there are at least 500,000 households making \$150,000 per year,
- the median age is less than 35.5, or
- the density of inhabitants is at least 1400 (per square kilometer).

```{python}
sel_counties = CA_stats[(CA_stats['high_earners'] >= 100000) & (CA_stats['median_age'] < 38.5) & (CA_stats['density'] >= 285) &
                        ((CA_stats['high_earners'] >= 500000) | (CA_stats['median_age'] < 35.5) | (CA_stats['density'] >= 1400))]
sel_counties
```

### 5) How many stores did you identify?

When looking for the next Starbucks Reserve Roastery location, you'd like to consider all of the stores within the counties that you selected.  So, how many stores are within the selected counties?

To prepare to answer this question, run the next code cell to create a GeoDataFrame `starbucks_gdf` with all of the starbucks locations.

```{python}
starbucks_gdf = gpd.GeoDataFrame(starbucks, geometry = gpd.points_from_xy(starbucks.Longitude, starbucks.Latitude))
starbucks_gdf.crs = {'init': 'epsg:4326'}
starbucks_gdf.head()
```

So, how many stores are in the counties you selected?

```{python}
county_stores = gpd.sjoin(sel_counties, starbucks_gdf)
num_stores = len(county_stores)
num_stores
```

### 6) Visualize the store locations.

Create a map that shows the locations of the stores that you identified in the previous question.

```{python}
# Create a base map
m_6 = folium.Map(location = [37, -120], zoom_start = 6)

# Show selected store locations
mc = MarkerCluster()

county_stores = gpd.sjoin(sel_counties, starbucks_gdf)

for idx, row in county_stores.iterrows() :
    if not math.isnan(row['Longitude']) and not math.isnan(row['Latitude']):
        mc.add_child(folium.Marker([row['Latitude'], row['Longitude']]))

m_6.add_child(mc)

# Show the map
embed_map(m_6, 'q_6.html')

m_6
```

# Keep going

Learn about how **[proximity analysis](https://www.kaggle.com/alexisbcook/proximity-analysis)** can help you to understand the relationships between points on a map.

---




*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/geospatial-analysis/discussion) to chat with other learners.*

